# LocalFlow

**Local-first AI workflow automation platform**

Build, run, and automate AI workflows entirely on your local machine - no cloud required.

## What is LocalFlow?

LocalFlow is a **local AI agent framework**. You design workflows visually, connect tools, and let a local AI decide how to use them to complete tasks. It's like giving an AI a toolbox and watching it figure out what to do.

**Everything runs locally.** No API keys. No cloud. No data leaves your machine.

---

## Key Features

### ğŸ¨ Visual Workflow Builder
Drag & drop nodes, connect them, run workflows with real-time progress.

### ğŸ¤– AI Orchestrator
An autonomous agent that examines available tools, plans a sequence, and executes step-by-step.

### ğŸ”§ 11 Built-in Tools
AI tools (name generator, color picker, trait generator, backstory), utility (calculator, datetime, ID generator), file operations, HTTP, shell, and more.

### ğŸ”Œ Plugin System
Drop a folder in `~/.localflow/plugins/` â†’ auto-discovered on startup. Create custom tools with simple JavaScript.

### ğŸ’¬ Master AI Chat
A conversational interface that knows the entire system. Ask it to explain, design, or build workflows.

### ğŸŒ Full API Access
- **REST API** (port 9998): List templates, run workflows, chat with Master AI
- **WebSocket** (port 9999): Real-time execution streaming
- **MCP Server**: Use LocalFlow from Claude Desktop

### ğŸ§  Local LLM
Runs Llama 3.2, Qwen, SmolLM models locally via llama.cpp. Download models in-app.

---

## Quick Start

```bash
npm install
npm run dev
```

1. **Load a Model**: Models tab â†’ Download â†’ Load
2. **Pick a Template**: Templates tab â†’ Click to load
3. **Run**: Click the green Run button

---

## API Examples

```bash
# List available workflows
curl http://localhost:9998/templates

# Run a workflow
curl -X POST http://localhost:9998/run \
  -H "Content-Type: application/json" \
  -d '{"templateId": "ai-character-builder"}'

# Chat with Master AI
curl -X POST http://localhost:9998/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What can you do?"}'
```

---

## Claude Desktop Integration (MCP)

LocalFlow can be used as a tool from Claude Desktop.

1. Add to `~/Library/Application Support/Claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "localflow": {
      "command": "node",
      "args": ["/path/to/localflow/mcp-server/index.js"]
    }
  }
}
```

2. Restart Claude Desktop
3. Say: "Use localflow to run the character builder"

See [mcp-server/README.md](mcp-server/README.md) for details.

---

## Creating Plugins

```
~/.localflow/plugins/my-plugin/
â”œâ”€â”€ manifest.json
â””â”€â”€ tools/
    â””â”€â”€ my-tool.js
```

See [PLUGIN_ARCHITECTURE.md](PLUGIN_ARCHITECTURE.md) for full guide.

---

## Documentation

| Doc | Description |
|-----|-------------|
| [REST_API.md](docs/REST_API.md) | HTTP endpoints |
| [WEBSOCKET_API.md](docs/WEBSOCKET_API.md) | Real-time streaming |
| [CHAT_API.md](docs/CHAT_API.md) | Master AI chat with sessions |
| [PLUGIN_ARCHITECTURE.md](PLUGIN_ARCHITECTURE.md) | Creating plugins |
| [ARCHITECTURE.md](ARCHITECTURE.md) | System design |
| [TODO.md](TODO.md) | Roadmap |

---

## Project Structure

```
localflow/
â”œâ”€â”€ electron/main/     # Backend (LLM, executor, plugins, APIs)
â”œâ”€â”€ src/               # React frontend
â”œâ”€â”€ mcp-server/        # MCP server for Claude Desktop
â”œâ”€â”€ docs/              # API documentation
â””â”€â”€ examples/          # Example clients
```

---

## What's Complete

- âœ… Visual workflow builder
- âœ… AI Orchestrator (autonomous tool selection)
- âœ… 11 built-in tools
- âœ… Plugin system (auto-discovery)
- âœ… REST API with schema discovery
- âœ… WebSocket real-time streaming
- âœ… Master AI Chat (with session memory)
- âœ… MCP Server (Claude Desktop integration)

## What's Next

- ğŸ”² Workflow-to-workflow (composable agents)
- ğŸ”² Persistence (save/load custom workflows)
- ğŸ”² UI polish

---

## License

MIT
